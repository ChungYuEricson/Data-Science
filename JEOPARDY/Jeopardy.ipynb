{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f13db971",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:220%\"> Analyzing Jeopardy Data Using Chi-Squared Test</h1>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c22bd78",
   "metadata": {},
   "source": [
    "Jeopardy is a popular TV show in the US where participants answer questions to win money. It's been running for many years, and is a major force in popular culture. In each game, contestants are presented trivia clues phrased as answers, to which they must respond in the form of a question that correctly identifies whatever the clue is describing. This project aims to find out if there are any patterns that would lead to a better chance of winning. The dataset can be downloaded [here(last updated in OCT 2021)](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039f7ba7",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:160%\"> TABLE OF CONTENTS </h1>\n",
    "\n",
    "<a id=\"0\"></a>\n",
    "\n",
    ">- [Read CSV File](#1)\n",
    ">- [Summary of Columns](#2)\n",
    ">- [Normalizing text](#3)\n",
    ">- [Study](#4)\n",
    ">    - [A) Answers in Questions](#5)\n",
    ">    - [B) Repeated Words in Questions](#6)\n",
    ">- [Identifying High Value and Low Value](#7)\n",
    ">- [Chi-Squared Test](#8)\n",
    ">- [Identifying High Frequencies](#9)\n",
    ">- [Chi-Squared Test with High Frequencies](#10)\n",
    ">- [Conclusion](#11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86eed113",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<h1 style=\"font-size:160%\"> Read CSV File</h1>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "648cd102-7d15-440a-afe6-b5f15bf5083b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216925</th>\n",
       "      <td>4999</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>RIDDLE ME THIS</td>\n",
       "      <td>$2000</td>\n",
       "      <td>This Puccini opera turns on the solution to 3 ...</td>\n",
       "      <td>Turandot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216926</th>\n",
       "      <td>4999</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>\"T\" BIRDS</td>\n",
       "      <td>$2000</td>\n",
       "      <td>In North America this term is properly applied...</td>\n",
       "      <td>a titmouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216927</th>\n",
       "      <td>4999</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>AUTHORS IN THEIR YOUTH</td>\n",
       "      <td>$2000</td>\n",
       "      <td>In Penny Lane, where this \"Hellraiser\" grew up...</td>\n",
       "      <td>Clive Barker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216928</th>\n",
       "      <td>4999</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>QUOTATIONS</td>\n",
       "      <td>$2000</td>\n",
       "      <td>From Ft. Sill, Okla. he made the plea, Arizona...</td>\n",
       "      <td>Geronimo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216929</th>\n",
       "      <td>4999</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>Final Jeopardy!</td>\n",
       "      <td>HISTORIC NAMES</td>\n",
       "      <td>None</td>\n",
       "      <td>A silent movie title includes the last name of...</td>\n",
       "      <td>Grigori Alexandrovich Potemkin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216930 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Show Number    Air Date             Round  \\\n",
       "0              4680  2004-12-31         Jeopardy!   \n",
       "1              4680  2004-12-31         Jeopardy!   \n",
       "2              4680  2004-12-31         Jeopardy!   \n",
       "3              4680  2004-12-31         Jeopardy!   \n",
       "4              4680  2004-12-31         Jeopardy!   \n",
       "...             ...         ...               ...   \n",
       "216925         4999  2006-05-11  Double Jeopardy!   \n",
       "216926         4999  2006-05-11  Double Jeopardy!   \n",
       "216927         4999  2006-05-11  Double Jeopardy!   \n",
       "216928         4999  2006-05-11  Double Jeopardy!   \n",
       "216929         4999  2006-05-11   Final Jeopardy!   \n",
       "\n",
       "                               Category  Value  \\\n",
       "0                               HISTORY   $200   \n",
       "1       ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2           EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3                      THE COMPANY LINE   $200   \n",
       "4                   EPITAPHS & TRIBUTES   $200   \n",
       "...                                 ...    ...   \n",
       "216925                   RIDDLE ME THIS  $2000   \n",
       "216926                        \"T\" BIRDS  $2000   \n",
       "216927           AUTHORS IN THEIR YOUTH  $2000   \n",
       "216928                       QUOTATIONS  $2000   \n",
       "216929                   HISTORIC NAMES   None   \n",
       "\n",
       "                                                 Question  \\\n",
       "0       For the last 8 years of his life, Galileo was ...   \n",
       "1       No. 2: 1912 Olympian; football star at Carlisl...   \n",
       "2       The city of Yuma in this state has a record av...   \n",
       "3       In 1963, live on \"The Art Linkletter Show\", th...   \n",
       "4       Signer of the Dec. of Indep., framer of the Co...   \n",
       "...                                                   ...   \n",
       "216925  This Puccini opera turns on the solution to 3 ...   \n",
       "216926  In North America this term is properly applied...   \n",
       "216927  In Penny Lane, where this \"Hellraiser\" grew up...   \n",
       "216928  From Ft. Sill, Okla. he made the plea, Arizona...   \n",
       "216929  A silent movie title includes the last name of...   \n",
       "\n",
       "                                Answer  \n",
       "0                           Copernicus  \n",
       "1                           Jim Thorpe  \n",
       "2                              Arizona  \n",
       "3                           McDonald's  \n",
       "4                           John Adams  \n",
       "...                                ...  \n",
       "216925                        Turandot  \n",
       "216926                      a titmouse  \n",
       "216927                    Clive Barker  \n",
       "216928                        Geronimo  \n",
       "216929  Grigori Alexandrovich Potemkin  \n",
       "\n",
       "[216930 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "jeopardy = pd.read_csv(\"JEOPARDY_CSV.csv\")\n",
    "jeopardy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88e907e",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "<h1 style=\"font-size:160%\"> Summary of Columns</h1>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370497b5",
   "metadata": {},
   "source": [
    "|Columns||Description|\n",
    "|---||:------------------|\n",
    "|index||Row number|\n",
    "|Show Number||The code for each episode|\n",
    "|Air Date||The date the episode aired|\n",
    "|Round||The round of Jeopardy that question was asked in|\n",
    "|Category||Type of the question|\n",
    "|Value||Amount of money that question can get|\n",
    "|Question||Text of question|\n",
    "|Answer||Text of answer|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1396aa",
   "metadata": {},
   "source": [
    "Remove spaces between columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0371a4d3-1ba8-4ebc-a1cb-92453f7abf77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "824329dd-df09-4ffc-bf52-5b20eee60d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy.columns = ['Show_Number', 'Air_Date', 'Round', 'Category', 'Value', 'Question', 'Answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087ba30b",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "<h1 style=\"font-size:160%\"> Normalizing text</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625e44d7",
   "metadata": {},
   "source": [
    "Before analyzing, the text needs to be normalize so that its easier to work with. For example, all the text needs to be in lowercase, the dollar sign in value column needs to be removed and etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0b52ac3-914d-484c-9a3e-0036e37ae586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def norm_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"[^A-Za-z0-9\\s]\", \"\", text)\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "def norm_values(text):\n",
    "    text = re.sub(\"[^A-Za-z0-9\\s]\", \"\", text)\n",
    "    try:\n",
    "        text = int(text)\n",
    "    except:\n",
    "        text = 0\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1875dbe8-1f9e-482e-913d-3ade6592be19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show_Number</th>\n",
       "      <th>Air_Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "      <th>clean_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>for the last 8 years of his life galileo was u...</td>\n",
       "      <td>copernicus</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>no 2 1912 olympian football star at carlisle i...</td>\n",
       "      <td>jim thorpe</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>the city of yuma in this state has a record av...</td>\n",
       "      <td>arizona</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>in 1963 live on the art linkletter show this c...</td>\n",
       "      <td>mcdonalds</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>signer of the dec of indep framer of the const...</td>\n",
       "      <td>john adams</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show_Number   Air_Date      Round                         Category Value  \\\n",
       "0         4680 2004-12-31  Jeopardy!                          HISTORY  $200   \n",
       "1         4680 2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES  $200   \n",
       "2         4680 2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...  $200   \n",
       "3         4680 2004-12-31  Jeopardy!                 THE COMPANY LINE  $200   \n",
       "4         4680 2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES  $200   \n",
       "\n",
       "                                            Question      Answer  \\\n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus   \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe   \n",
       "2  The city of Yuma in this state has a record av...     Arizona   \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's   \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams   \n",
       "\n",
       "                                      clean_question clean_answer  clean_value  \n",
       "0  for the last 8 years of his life galileo was u...   copernicus          200  \n",
       "1  no 2 1912 olympian football star at carlisle i...   jim thorpe          200  \n",
       "2  the city of yuma in this state has a record av...      arizona          200  \n",
       "3  in 1963 live on the art linkletter show this c...    mcdonalds          200  \n",
       "4  signer of the dec of indep framer of the const...   john adams          200  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[\"Answer\"]=jeopardy['Answer'].astype(str)\n",
    "jeopardy[\"clean_question\"] = jeopardy[\"Question\"].apply(norm_text)\n",
    "jeopardy[\"clean_answer\"] = jeopardy[\"Answer\"].apply(norm_text)\n",
    "jeopardy[\"clean_value\"] = jeopardy[\"Value\"].apply(norm_values)\n",
    "jeopardy[\"Air_Date\"]= pd.to_datetime(jeopardy[\"Air_Date\"])\n",
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c954f573-5533-412c-bc23-1952c05717c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Show_Number                int64\n",
       "Air_Date          datetime64[ns]\n",
       "Round                     object\n",
       "Category                  object\n",
       "Value                     object\n",
       "Question                  object\n",
       "Answer                    object\n",
       "clean_question            object\n",
       "clean_answer              object\n",
       "clean_value                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc91be1",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<h1 style=\"font-size:160%\"> Study</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67277cbb",
   "metadata": {},
   "source": [
    "Answers in Questions\n",
    "In order to figure out whether to study past questions, study general knowledge, or not study it all, it would be helpful to figure out two things:\n",
    "\n",
    ">- How often the answer can be used for a question.\n",
    ">- How often questions are repeated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea75b372",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "<h1 style=\"font-size: 135%\">A) Answers in Questions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "509f202a-b64b-4e8e-93ac-649c5a235bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_matches(row):\n",
    "    split_answer = row[\"clean_answer\"].split()\n",
    "    split_question = row[\"clean_question\"].split()\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    for item in split_answer:\n",
    "        if item in split_question:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "a = jeopardy.apply(count_matches, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3fd5cfb-b8d6-4581-9fbc-e0b85a4a10a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a[a==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c9b8539-c010-4969-b9d7-da2905719e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5         True\n",
       "6         True\n",
       "11        True\n",
       "14        True\n",
       "18        True\n",
       "          ... \n",
       "216871    True\n",
       "216877    True\n",
       "216886    True\n",
       "216898    True\n",
       "216908    True\n",
       "Length: 25782, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7151e887",
   "metadata": {},
   "source": [
    "There are 25782 sets of questions and answers that matched.<br>\n",
    "Inspect the details to look for unwanted results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b942a5a9-a522-4778-980b-c52bfb578e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('In the title of an Aesop fable, this insect shared billing with a grasshopper',\n",
       " 'the ant')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.loc[5,\"Question\"],jeopardy.loc[5,\"Answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6317fe20-79a3-40ea-a3b1-d4d7119e2d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('It can be a place to leave your puppy when you take a trip, or a carrier for him that fits under an airplane seat',\n",
       " 'a kennel')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.loc[31,\"Question\"],jeopardy.loc[31,\"Answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4641b1c",
   "metadata": {},
   "source": [
    "A lot of these matches occurred due to common words such as 'the' , 'a' and etc.<br>\n",
    "#### Introducing stopwords to eliminate all the common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8d19887-99e9-4819-bb2d-16e1ade2d3e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cyeri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cyeri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72510932",
   "metadata": {},
   "source": [
    "#### Create a function that filters answers and calculate the ratio of number of words in the answer that are found in questions. \n",
    "#### Apply the function to every row of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51ecbad9-3f3a-4ffc-8f75-cb2c4d458fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def count_matches(row):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    question_tokens = word_tokenize(row[\"clean_question\"])\n",
    "    answer_tokens = word_tokenize(row[\"clean_answer\"])\n",
    "    filtered_answer = [w for w in answer_tokens if not w in stop_words]\n",
    "    \n",
    "    if len(filtered_answer) == 0:\n",
    "        return 0\n",
    "    \n",
    "    match_count = 0\n",
    "    for item in filtered_answer:\n",
    "        if item in question_tokens:\n",
    "            match_count += 1\n",
    "    return match_count / len(filtered_answer)\n",
    "\n",
    "jeopardy[\"answer_in_question\"] = jeopardy.apply(count_matches, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72e893d7-0d9e-4c55-ac37-e2001e03d31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038456264050234445"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[\"answer_in_question\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464f2cd6",
   "metadata": {},
   "source": [
    "On average, about 3% of words could be found in questions. Chances of not needing to prepare for the game and winning is rather low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213e9121",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "<h1 style=\"font-size: 135%\">B) Repeated Words in Questions</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2cf550",
   "metadata": {},
   "source": [
    "Another approach would be checking if certain term is being repeated over the many questions. Adding another condition of omiting words under 5 character would ensure the results to be specific terminology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfa6e57f-a4a9-485d-9602-b60fe9ffc45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_overlap = []\n",
    "terms_used = set()\n",
    "\n",
    "jeopardy = jeopardy.sort_values(\"Air_Date\")\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for i, row in jeopardy.iterrows():\n",
    "        split_question = row[\"clean_question\"].split(\" \")\n",
    "        split_question = [w for w in split_question if len(w) > 5 if not w in stop_words]\n",
    "        match_count = 0\n",
    "        for word in split_question:\n",
    "            if word in terms_used:\n",
    "                match_count += 1\n",
    "        for word in split_question:\n",
    "            terms_used.add(word)\n",
    "        if len(split_question) > 0:\n",
    "            match_count /= len(split_question)\n",
    "        question_overlap.append(match_count)\n",
    "jeopardy[\"question_overlap\"] = question_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58705cda-7ad0-4461-b749-ab45e676bc89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8704485294555635"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.question_overlap.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f56334",
   "metadata": {},
   "source": [
    "On average, about 87% chance a specific terminology has been repeated as least once throughout the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd3ec80",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "<h1 style=\"font-size:160%\"> Identifying High Value and Low Value</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefb034b",
   "metadata": {},
   "source": [
    "It is important to be able to identify the difference of values within questions to increase the chances of winning. Then we can identify the terms that are corresponded to high-value questions using chi-squared test. To do that:\n",
    "\n",
    "First, split and store value into two categories:\n",
    "> - Low value : Row where value column is less than 800\n",
    "> - High value : Row where value column is more than 800\n",
    "\n",
    "Second, create a counter that counts the frequency of the high value or low value by checking if the if question contains the term.\n",
    "\n",
    "Third, for every term in term_used, store the results of the function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9442194-b19e-40b0-b094-9e054ece53d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_value(row):\n",
    "    value = 0\n",
    "    if row[\"clean_value\"]>800:\n",
    "        value +=1\n",
    "    else:\n",
    "        value = 0\n",
    "    return value\n",
    "\n",
    "jeopardy[\"high_value\"] = jeopardy.apply(find_value,axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b01ca09-d56f-4a90-a30d-b1a67804b6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_count(w):\n",
    "    high_count = 0\n",
    "    low_count = 0\n",
    "    \n",
    "    pattern = r\"\\b{}\\b\".format(w)\n",
    "    high_count = jeopardy[(jeopardy['clean_question'].str.contains(pattern, regex = True)) &\n",
    "                         (jeopardy['high_value'] == 1)]['high_value'].count()\n",
    "    low_count = jeopardy[(jeopardy['clean_question'].str.contains(pattern, regex = True)) &\n",
    "                        (jeopardy['high_value'] == 0)]['high_value'].count()\n",
    "    return w, high_count, low_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf4f142e-81d0-416c-8e96-13381923f777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "terms_used_list = list(terms_used)\n",
    "comparison_terms = [choice(terms_used_list) for _ in range(10)]\n",
    "\n",
    "observed_expected = []\n",
    "\n",
    "for term in comparison_terms:\n",
    "    observed_expected.append(value_count(term))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c74b23",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a>\n",
    "<h1 style=\"font-size:160%\"> Chi-Squared Test</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e28c1",
   "metadata": {},
   "source": [
    "Fourth, get sum of high value and low value to calculate for observed and expected value to perform Chi-squared test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "982236b9-0db5-4232-ba9b-a4054697120b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>high_value</th>\n",
       "      <th>low_value</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hangin</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hrefhttpwwwjarchivecommedia20040528dj20jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hrefhttpwwwjarchivecommedia20060630dj28jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hrefhttpwwwjarchivecommedia20080602dj18mp3dag</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>icedancing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xiaoping</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>negron</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hrefhttpwwwjarchivecommedia20091209dj26wmvalex</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>moranis</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>saluton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             word  high_value  low_value  \\\n",
       "0                                          hangin           2          2   \n",
       "1      hrefhttpwwwjarchivecommedia20040528dj20jpg           0          1   \n",
       "2      hrefhttpwwwjarchivecommedia20060630dj28jpg           1          0   \n",
       "3   hrefhttpwwwjarchivecommedia20080602dj18mp3dag           1          0   \n",
       "4                                      icedancing           1          0   \n",
       "5                                        xiaoping           1          2   \n",
       "6                                          negron           0          1   \n",
       "7  hrefhttpwwwjarchivecommedia20091209dj26wmvalex           0          1   \n",
       "8                                         moranis           1          0   \n",
       "9                                         saluton           1          0   \n",
       "\n",
       "   total  \n",
       "0      4  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  \n",
       "5      3  \n",
       "6      1  \n",
       "7      1  \n",
       "8      1  \n",
       "9      1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "\n",
    "high_value_count = jeopardy[jeopardy[\"high_value\"] == 1].shape[0]\n",
    "low_value_count = jeopardy[jeopardy[\"high_value\"] == 0].shape[0]\n",
    "\n",
    "observed_expected =list(observed_expected)\n",
    "df = pd.DataFrame(observed_expected,columns = ['word',\"high_value\",\"low_value\"])\n",
    "df[\"total\"] = df[\"high_value\"]+df[\"low_value\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5e42283-0460-424f-99f9-e4cee2e6bd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(hangin, 0.9267728889671603, 0.33570289422995...\n",
       "1    [(hrefhttpwwwjarchivecommedia20040528dj20jpg, ...\n",
       "2    [(hrefhttpwwwjarchivecommedia20060630dj28jpg, ...\n",
       "3    [(hrefhttpwwwjarchivecommedia20080602dj18mp3da...\n",
       "4    [(icedancing, 2.5317964247338085, 0.1115731283...\n",
       "5    [(xiaoping, 0.03723409388907139, 0.84698921448...\n",
       "6    [(negron, 0.3949764642333513, 0.52969509124866...\n",
       "7    [(hrefhttpwwwjarchivecommedia20091209dj26wmval...\n",
       "8    [(moranis, 2.5317964247338085, 0.1115731283816...\n",
       "9    [(saluton, 2.5317964247338085, 0.1115731283816...\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cal_chi_square(row):\n",
    "    chi_squared = []\n",
    "    total_prop = row['total']/jeopardy.shape[0]\n",
    "    high_value_exp = total_prop * high_value_count\n",
    "    low_value_exp = total_prop * low_value_count\n",
    "    observed = np.array([row['high_value'], row['low_value']])\n",
    "    expected = np.array([high_value_exp, low_value_exp])\n",
    "    \n",
    "    chi_value, p_value = chisquare(observed, expected)\n",
    "    \n",
    "    chi_squared.append((row['word'], chi_value, p_value, row['high_value'], row['low_value']))\n",
    "    return chi_squared\n",
    "                         \n",
    "    \n",
    "chi_squared = df.apply(cal_chi_square, axis = 1)\n",
    "chi_squared\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0ed68b",
   "metadata": {},
   "source": [
    "None of the above results give a p-value of less than 5 percent, chi-squared test is not valid, there is no significant difference in usage in high value and low value for these words. The test would give better results if run with terms with higher frequencies. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553da280",
   "metadata": {},
   "source": [
    "<a id=\"9\"></a>\n",
    "<h1 style=\"font-size:160%\"> Identifying High Frequencies</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7134f240",
   "metadata": {},
   "source": [
    "To identify frequencies, a new frequency counter that only focuses on occurrence of terms is required to optimize run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24f7af95-1fa5-4d1b-8c34-1e78f7131094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       nominations\n",
       "1                                           ardenne\n",
       "2        hrefhttpwwwjarchivecommedia20110112j10ajpg\n",
       "3                                          petunias\n",
       "4                                            lawful\n",
       "                            ...                    \n",
       "99893                              targetblankhawka\n",
       "99894                               vixenoffroadcom\n",
       "99895                                      redskins\n",
       "99896                                       glasser\n",
       "99897                                        deeper\n",
       "Length: 99898, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms_used_sr = pd.Series(list(terms_used))\n",
    "terms_used_sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "009326cb-d322-46d5-874b-7d35d2c71fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_counter(w):\n",
    "    pattern = r\"\\b{}\\b\".format(w)\n",
    "    freq = sum(jeopardy['clean_question'].str.contains(pattern, regex = True))\n",
    "    return w,freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad54b3c",
   "metadata": {},
   "source": [
    "The run time would take too long for the scope of this project, we would choose 5000 random terms to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "726179a0-88eb-49a1-ba05-4f0d59353e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "freq_comparison_terms = pd.Series([choice(terms_used_list) for _ in range(5000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f0ecd2d0-2e60-439b-b63a-b8aac6b3b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = freq_comparison_terms.apply(freq_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ecba3e",
   "metadata": {},
   "source": [
    "The first test proved chi-squared test would not be effective with low frequencies data. This test would limit occurrence to above 20 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "6b750869-70a0-40b7-a35f-a69d31b9be77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>around</td>\n",
       "      <td>1777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4247</th>\n",
       "      <td>states</td>\n",
       "      <td>1359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>ancient</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>center</td>\n",
       "      <td>902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>nation</td>\n",
       "      <td>854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>envelope</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4286</th>\n",
       "      <td>highflying</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>mideastern</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4728</th>\n",
       "      <td>bridal</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>remedy</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>325 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  freq\n",
       "1301      around  1777\n",
       "4247      states  1359\n",
       "385      ancient   912\n",
       "3984      center   902\n",
       "243       nation   854\n",
       "...          ...   ...\n",
       "1338    envelope    21\n",
       "4286  highflying    21\n",
       "1791  mideastern    21\n",
       "4728      bridal    21\n",
       "1330      remedy    21\n",
       "\n",
       "[325 rows x 2 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_freq_w = pd.DataFrame(list(frequency),columns = ['word','freq']).sort_values(by=\"freq\",ascending=False)\n",
    "high_freq_w = high_freq_w[high_freq_w[\"freq\"]>20]\n",
    "high_freq_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851dba55",
   "metadata": {},
   "source": [
    "<a id=\"10\"></a>\n",
    "<h1 style=\"font-size:160%\"> Chi-Squared Test with High Frequencies</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "16855f30-db4a-4a47-8c14-41830f903a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>high_value</th>\n",
       "      <th>low_value</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>around</td>\n",
       "      <td>521</td>\n",
       "      <td>1256</td>\n",
       "      <td>1777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>states</td>\n",
       "      <td>360</td>\n",
       "      <td>999</td>\n",
       "      <td>1359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ancient</td>\n",
       "      <td>292</td>\n",
       "      <td>620</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>center</td>\n",
       "      <td>291</td>\n",
       "      <td>611</td>\n",
       "      <td>902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nation</td>\n",
       "      <td>269</td>\n",
       "      <td>585</td>\n",
       "      <td>854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>envelope</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>highflying</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>mideastern</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>bridal</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>remedy</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>325 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  high_value  low_value  total\n",
       "0        around         521       1256   1777\n",
       "1        states         360        999   1359\n",
       "2       ancient         292        620    912\n",
       "3        center         291        611    902\n",
       "4        nation         269        585    854\n",
       "..          ...         ...        ...    ...\n",
       "320    envelope           2         19     21\n",
       "321  highflying           3         18     21\n",
       "322  mideastern           8         13     21\n",
       "323      bridal           4         17     21\n",
       "324      remedy           3         18     21\n",
       "\n",
       "[325 rows x 4 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_freq_w_list = high_freq_w[\"word\"]\n",
    "high_low_value_table = high_freq_w_list.apply(value_count)\n",
    "high_low_value_table = pd.DataFrame(list(high_low_value_table),columns=['word','high_value','low_value'])\n",
    "high_low_value_table[\"total\"] = high_low_value_table[\"high_value\"]+high_low_value_table[\"low_value\"]\n",
    "high_low_value_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f7590057-8495-48cc-ab5a-62bfa16545c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [(around, 0.8840432228440693, 0.34709665951509...\n",
       "1      [(states, 2.2279050234367053, 0.13553751336244...\n",
       "2      [(ancient, 6.162328080925132, 0.01304993395438...\n",
       "3      [(center, 6.924680318118202, 0.008501418791956...\n",
       "4      [(nation, 4.267144686676575, 0.038856170473074...\n",
       "                             ...                        \n",
       "320    [(envelope, 3.653032823198812, 0.0559672105782...\n",
       "321    [(highflying, 2.0361210587719096, 0.1536008974...\n",
       "322    [(mideastern, 0.9898092208761973, 0.3197890070...\n",
       "323    [(bridal, 0.8884257599609271, 0.34590426880223...\n",
       "324    [(remedy, 2.0361210587719096, 0.15360089742564...\n",
       "Length: 325, dtype: object"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_freq_chi_squared = high_low_value_table.apply(cal_chi_square, axis = 1)\n",
    "high_freq_chi_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "405906a9-e9d3-466b-a655-9af1e6e6b6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>chi_squared</th>\n",
       "      <th>p_value</th>\n",
       "      <th>high_value</th>\n",
       "      <th>low_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>around</td>\n",
       "      <td>0.884043</td>\n",
       "      <td>0.347097</td>\n",
       "      <td>521</td>\n",
       "      <td>1256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>states</td>\n",
       "      <td>2.227905</td>\n",
       "      <td>0.135538</td>\n",
       "      <td>360</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ancient</td>\n",
       "      <td>6.162328</td>\n",
       "      <td>0.013050</td>\n",
       "      <td>292</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>center</td>\n",
       "      <td>6.924680</td>\n",
       "      <td>0.008501</td>\n",
       "      <td>291</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nation</td>\n",
       "      <td>4.267145</td>\n",
       "      <td>0.038856</td>\n",
       "      <td>269</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>envelope</td>\n",
       "      <td>3.653033</td>\n",
       "      <td>0.055967</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>highflying</td>\n",
       "      <td>2.036121</td>\n",
       "      <td>0.153601</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>mideastern</td>\n",
       "      <td>0.989809</td>\n",
       "      <td>0.319789</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>bridal</td>\n",
       "      <td>0.888426</td>\n",
       "      <td>0.345904</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>remedy</td>\n",
       "      <td>2.036121</td>\n",
       "      <td>0.153601</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>325 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  chi_squared   p_value  high_value  low_value\n",
       "0        around     0.884043  0.347097         521       1256\n",
       "1        states     2.227905  0.135538         360        999\n",
       "2       ancient     6.162328  0.013050         292        620\n",
       "3        center     6.924680  0.008501         291        611\n",
       "4        nation     4.267145  0.038856         269        585\n",
       "..          ...          ...       ...         ...        ...\n",
       "320    envelope     3.653033  0.055967           2         19\n",
       "321  highflying     2.036121  0.153601           3         18\n",
       "322  mideastern     0.989809  0.319789           8         13\n",
       "323      bridal     0.888426  0.345904           4         17\n",
       "324      remedy     2.036121  0.153601           3         18\n",
       "\n",
       "[325 rows x 5 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([c[0] for c in high_freq_chi_squared], \n",
    "                              columns = ['word', 'chi_squared', 'p_value', 'high_value', 'low_value'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "01f960be-9b4e-4458-b0c4-ce154fecfc6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.418165706598223"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"p_value\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c99bf6c",
   "metadata": {},
   "source": [
    "The overall results are still not ideal. However, there is a great increase in effectiveness, as many terms have a p value of 5 percent. This may due to the 5000 terms limit that was set earlier and also the study may need a better solution to filter out words such as around, center and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbee7ad",
   "metadata": {},
   "source": [
    "<a id=\"11\"></a>\n",
    "<h1 style=\"font-size:160%\"> Conclusion</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0f8b39",
   "metadata": {},
   "source": [
    "The project aims to find patterns that would increase chances of winning Jeopardy. After studying the data, we know that:\n",
    "> - On average, about 3% of words could be found in questions. Chances of not needing to prepare for the game and winning is rather low.\n",
    "> - On average, about 87% chance a specific terminology has been repeated as least once throughout the dataset.\n",
    "> - In order to draw correlation between specific words and high value questions, we need to limit the study to only high frequency terms\n",
    "\n",
    "Next step after this project would be increasing the sample size to the full list of terms. Identify words where high value ocurrence exceeds low value. After that, find the category or questions these terms fall into."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
